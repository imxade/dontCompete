{
  "id": "28",
  "stream": "electronics-and-communication-engineering",
  "packet": "2022",
  "year": "2022",
  "type": "MSQ",
  "key": "A, B, C \nSol.\n \nGiven : \n \n( )\nH X\n  is entropy of a discrete random variable \nX \ntaking \nK\n possible distinct real values.\nLet variable \nX\n  is taking values as \ni\nx\n  so set of possible values is \n\uf07b\n\uf07d\n1\n2\n3\n,\n,\n.......\n k\nx x x\nx\n.\n1\n(\n)\n( )log\n( )\nk\ni\ni\ni\nH X\nP x\nP x\n\uf03d\n\uf03d\n\uf0e5\nThe entropy will be,\n1\nNote :\n Base 2 of log gives the unit of \u201cbits\u201d or \u201cShannon\u2019s\u201d, base \ne\n gives natural unit \n\"nat\"\nand base 10 \ngives unit of \n\"dits\"\n or \u201cHartley\u2019s\u201d.\nCase-1 : \nWhen all values are equiprobable i.e. \n1\n( )\ni\nP x\nK\n\uf03d\n for each distinct \n'\n'\nK\n  values, then entropy will\nbe given as,\n1\n1\n(\n)\nlog\nlog\n..........\ntimes\nH X\nK\nK\nK\nK\nK\n\uf03d\n\uf02b\n(\n)\nlog\nK\nH X\nK\nK\n\uf03d\n( )\nlog\nH X\nK\n\uf03d\n \n \nWhen we choose base as 2, \n \n2\n(\n)\nlog\nbits\nH X\nK\n\uf03d\nWe know that, in case of equal probability the entropy will be highest, \n \nSo, \n2\n(\n)\nlog\nH X\nK\n\uf0a3\n is always true for any base value.\nHence, option \n(A) \nis correct. \n \nCase-2 : \nAssuming a new random variable \n2\nY\nX\n\uf03d\n which is mapped by random variable \nX\n  as shown \nbelow,\n1\nx\n1\ny\n2\nx\n2\ny\ni\nx\ni\ny\nk\nx\nk\ny\n\uf04d\n\uf04d\nFigure: Mapping for \n2\nY\nX\n\uf03d\n\nGATE 2022 \n [Forenoon Session]\nElectronics & Communication Engineering\nPAGE\n38\n\nSo, mapping will be one to one as we have linear relation between \nX\n and \nY\n.  \n \nThe \nrandom \nvariable \n\uf07b\n\uf07d\n1\n2\n3\n,\n,\n.......\n k\nX\nx x x\nx\n\uf03d\nin \nthe \nsame \nway \nrandom \nvariable \nY\n\uf07b\n\uf07d\n1\n1\n2\n2\n2 ,\n2\n,..........\n2\nK\nK\nY\ny\nx y\nx\ny\nx\n\uf03d\n\uf03d\n\uf03d\n\uf03d\nAlong with values the probability of occurring each value will also be mapped and hence \ni\nx\n  and\ncorresponding \ni\ny\n will have identical probability, i. e. \n( )\n( )\ni\ni\nP x\nP y\n\uf03d\nWe can say that\n1\n1\n2\n2\n( )\n(\n), (\n)\n(\n).......... (\n)\n(\n)\nK\nK\nP x\nP y\nP x\nP y\nP x\nP y\n\uf03d\n\uf03d\n\uf03d\nProbability of random variable \nX\n and \nY\n  are same, because one to one mapping therefore, entropy of \nrandom variable \nX\n and \nY\n are same. i. e. \n(\n2 )\n( )\nH Y\nX\nH X\n\uf03d\n\uf03d\nSo we will never have situation of \n( )\n(2 )\nH X\nH\nX\n\uf03c\nHence, option \n(B)\n is correct  \nCase-3 : \nAssume new random variable \n2\nX\nY\n \uf03d\n,  This \n2\nX\nY\n \uf03d\n will give one to one mapping because \ndifferent values of\n X\n  provide different values of \nY\n  so that probability of random variable Y is same as \nprobabilities of random variable X so that entropy\n(\n2 )\n(\n)\nX\nH Y\nH X\n\uf03d\n\uf03d\nSo, \n(\n)\n(2 )\nX\nH X\nH\n\uf03c\n never occur\nSo, option (\nC)\n is also correct. \n \nCase-4 : \nAssuming new random variable \n2\nY\nX\n\uf03d\n. \nPossibility-01 : \nSuppose we have 3 positive values of random variable \nX\n  is \n1\n1\nx\n \uf03d\n, \n2\n2,\nx\n \uf03d\n \n3\n3\nx\n \uf03d\n and\nassuming corresponding probabilities of \n1\n2\n3\n,\n,\nx x x\n  are \n1 1 3\n,\n,\n5 2 10\nrespectively\ni.e. \n{1,\n2,\n3}\nX\n \uf03d\nProbability, \n\uf07b\n\uf07d\n1\n1\n3\n(\n)\n,\n,\n5\n2\n10\nP X\n \uf03d\nThus, random variable, \n2\n{1,4,9}\nY\nX\n\uf03d\n\uf03d\n \n \nHere we can say different values of X gives different values of Y, it shows one to one mapping is possible \nbetween X and Y.\nX\nY \nX\n= \n 2\n1\n1\nx\n \uf03d\n1\n1\ny\n \uf03d\n2\n2\nx\n \uf03d\n2\n4\ny\n \uf03d\n3\n3\nx\n \uf03d\n3\n9\ny\n \uf03d\nFig. One to one mapping \n \nSo, probabilities of random variable Y is same as probability of random variable \nX\n.\nIt means, \n1\n1\n3\n( )\n,\n,\n(\n)\n5\n2\n10\nP Y\nP X\n\uf0ec\n\uf0fc\n\uf03d\n\uf03d\n\uf0ed\n\uf0fd\n\uf0ee\n\uf0fe\n\nThus we can say that entropy of \n2\n(\n)\n(\n)\nH X\nH Y\nX\n\uf03d\n\uf03d\n\nGATE 2022 \n [Forenoon Session]\nElectronics & Communication Engineering\nPAGE\n39\n\nPossibility-02 :\n Suppose we have 3 negative values of random variable \nX\n  is \n1\n1\nx\n \uf03d\uf02d\n, \n2\n2\nx\n \uf03d\uf02d\n, \n3\n3\nx\n \uf03d\uf02d\nand assuming corresponding probabilities of \n1\n2\n3\n,\n,\nx x x\n  are \n1 1 3\n,\n,\n5 2 10\nrespectively\ni.e. \n{ 1,\n2,\n3}\nX\n \uf03d\uf02d\n\uf02d\n\uf02d\nProbability, \n\uf07b\n\uf07d\n1\n1\n3\n(\n)\n,\n,\n5\n2\n10\nP X\n \uf03d\nThus, random variable, \n2\n{1,4,9}\nY\nX\n\uf03d\n\uf03d\nHere we can say different values of \nX\n gives different values of \nY\n, it shows one to one mapping is possible \nbetween \nX\n and \nY\n.\nX\nY \nX\n= \n 2\n1\n1\nx\n \uf03d\uf02d\n1\n1\ny\n \uf03d\n2\n2\nx\n \uf03d\uf02d\n2\n4\ny\n \uf03d\n3\n3\nx\n \uf03d\uf02d\n3\n9\ny\n \uf03d\nFig. One to one mapping \n2\nY\nX\n\uf03d\n \n \nSo, probabilities of random variable \nY\n is same as probability of random variable \nX\n,\nIt means, \n1\n1\n3\n( )\n,\n,\n(\n)\n5\n2\n10\nP Y\nP X\n\uf0ec\n\uf0fc\n\uf03d\n\uf03d\n\uf0ed\n\uf0fd\n\uf0ee\n\uf0fe\n\nThus we can say that entropy of \n2\n(\n)\n(\n)\nH X\nH Y\nX\n\uf03d\n\uf03d\n.\nPossibility-03 :\n Suppose we have both positive and negative values of random varible X is \n1\n1\nx\n \uf03d\uf02d\n, \n2\n1\nx\n \uf03d\n, \n3\n2\nx\n \uf03d\n and assuming corresponding probabilities of \n1\nx\n , \n2\nx\n  and \n3\nx\n  are \n1\n5\n \n, \n1\n2\n \n and \n3 .\n10\ni.e. \n{ 1, 1,\n2}\nX\n \uf03d\uf02d\nProbability of \nX\n, \n1\n1\n3\n(\n)\n,\n,\n5\n2\n10\nP X\n\uf0ec\n\uf0fc\n\uf03d\uf0ed\n\uf0fd\n\uf0ee\n\uf0fe\n\nThus random variable, \n2\n{1, 1,\n4}\nY\nX\n\uf03d\n\uf03d\nHere we see different values of X gives same value of Y, it show one to one mapping is not possible here.\nX\nY \nX \n=\n2\n1\n1\nx\n \uf03d\uf02d\n1\n1\ny\n \uf03d\n2\n1\nx\n \uf03d\n3\n2\nx\n \uf03d\n2\n4\ny\n \uf03d\nFig. Mapping of \n2\nY\nX\n\uf03d\n \n \nSo, random variable \nY\n have only 2-values i.e. \n[1,4]\nY\n \uf03d\nSo, probability of \n1\n(\n1)\nP y\n \uf03d\n is sum of probability of \n1\n(\n1)\nP x\n \uf03d\uf02d\n and \n2\n(\n1)\nP x\n \uf03d\n so, \n1\n1\n1\n7\n(\n1)\n5\n2\n10\nP y\n \uf03d\n\uf03d\n\uf02b\n\uf03d\n\nGATE 2022 \n [Forenoon Session]\nElectronics & Communication Engineering\nPAGE\n40\n\nProbability of \n2\n(\n4)\nP y\n \uf03d\n remains same as probability of \n3\n(\n2)\nP x\n \uf03d\n.\ni.e.  \n2\n3\n3\n(\n4)\n(\n2)\n10\nP y\nP x\n\uf03d\n\uf03d\n\uf03d\n\uf03d\nSo entropy of \n( )\nH Y\n  is\n1\n1\n( )\n(\n1)log\n(\n4)log\n(\n1)\n(\n4)\nH Y\nP y\nP y\nP y\nP y\n\uf03d\n\uf03d\n\uf02b\n\uf03d\n\uf03d\n\uf03d\n1\n2\n2\n2\n1\n2\n\n2\n2\n7\n10\n3\n10\nlog\nlog\n10\n7\n10\n3\n\uf03d\n\uf02b\n0.265\n\uf03d\nEntropy of \n( )\nH X\n  is,\n1\n1\n1\n(\n1)log\n(\n1)log\n(\n2)log\n(\n1)\n(\n1)\n(\n2)\nP x\nP x\nP x\nP x\nP x\nP x\n\uf03d\n\uf03d\uf02d\n\uf02b\n\uf03d\n\uf02b\n\uf03d\n\uf03d\uf02d\n\uf03d\n\uf03d\n1\n2\n2\n2\n3\n2\n1\n2\n3\n2\n2\n2\n1\n1\n3\n10\nlog 5\nlog 2\nlog\n5\n2\n10\n3\n\uf03d\n\uf02b\n\uf02b\n0.4643 0.5 0.521089\n\uf03d\n\uf02b\n\uf02b\n1.4854\n\uf03d\nFrom Case-4, it is clear that \n2\n(\n)\n(\n)\nH X\nH X\n\uf03d\n is possible only when random variable \nX \nhave all positive or\nnegative values and \nX\n can take combination of positive and negative values then \n2\n(\n)\n(\n)\nH X\nH X\n\uf03e\n that \nwhy option (D) is incorrect.\nHence, the correct options are (A), (B) & (C).",
  "question_text": "Question 28 \n(MSQ)\n \n \n \nElectronic Devices\nSelect the correct statement(s) regarding CMOS implementation of NOT gates.\n(A) Noise Margin High \n(\n)\nH\nNM\n is always equal to the Noise Margin Low \n(\n)\nL\nNM\n irrespective of the sizing\nof transistors. \n \n(B) Mobility of electrons never influences the switching speed of the NOT gate. \n \n(C) For a logical high input under steady state, the \nn\n MOSFET is in the linear regime of operation. \n \n(D) Dynamic power consumption during switching is zero. \nAns. \nC\n\nGATE 2022 \n [Forenoon Session]\nElectronics & Communication Engineering\nPAGE\n34\n",
  "answer_text": "A, B, C \nSol.\n \nGiven : \n \n( )\nH X\n  is entropy of a discrete random variable \nX \ntaking \nK\n possible distinct real values.\nLet variable \nX\n  is taking values as \ni\nx\n  so set of possible values is \n\uf07b\n\uf07d\n1\n2\n3\n,\n,\n.......\n k\nx x x\nx\n.\n1\n(\n)\n( )log\n( )\nk\ni\ni\ni\nH X\nP x\nP x\n\uf03d\n\uf03d\n\uf0e5\nThe entropy will be,\n1\nNote :\n Base 2 of log gives the unit of \u201cbits\u201d or \u201cShannon\u2019s\u201d, base \ne\n gives natural unit \n\"nat\"\nand base 10 \ngives unit of \n\"dits\"\n or \u201cHartley\u2019s\u201d.\nCase-1 : \nWhen all values are equiprobable i.e. \n1\n( )\ni\nP x\nK\n\uf03d\n for each distinct \n'\n'\nK\n  values, then entropy will\nbe given as,\n1\n1\n(\n)\nlog\nlog\n..........\ntimes\nH X\nK\nK\nK\nK\nK\n\uf03d\n\uf02b\n(\n)\nlog\nK\nH X\nK\nK\n\uf03d\n( )\nlog\nH X\nK\n\uf03d\n \n \nWhen we choose base as 2, \n \n2\n(\n)\nlog\nbits\nH X\nK\n\uf03d\nWe know that, in case of equal probability the entropy will be highest, \n \nSo, \n2\n(\n)\nlog\nH X\nK\n\uf0a3\n is always true for any base value.\nHence, option \n(A) \nis correct. \n \nCase-2 : \nAssuming a new random variable \n2\nY\nX\n\uf03d\n which is mapped by random variable \nX\n  as shown \nbelow,\n1\nx\n1\ny\n2\nx\n2\ny\ni\nx\ni\ny\nk\nx\nk\ny\n\uf04d\n\uf04d\nFigure: Mapping for \n2\nY\nX\n\uf03d\n\nGATE 2022 \n [Forenoon Session]\nElectronics & Communication Engineering\nPAGE\n38\n\nSo, mapping will be one to one as we have linear relation between \nX\n and \nY\n.  \n \nThe \nrandom \nvariable \n\uf07b\n\uf07d\n1\n2\n3\n,\n,\n.......\n k\nX\nx x x\nx\n\uf03d\nin \nthe \nsame \nway \nrandom \nvariable \nY\n\uf07b\n\uf07d\n1\n1\n2\n2\n2 ,\n2\n,..........\n2\nK\nK\nY\ny\nx y\nx\ny\nx\n\uf03d\n\uf03d\n\uf03d\n\uf03d\nAlong with values the probability of occurring each value will also be mapped and hence \ni\nx\n  and\ncorresponding \ni\ny\n will have identical probability, i. e. \n( )\n( )\ni\ni\nP x\nP y\n\uf03d\nWe can say that\n1\n1\n2\n2\n( )\n(\n), (\n)\n(\n).......... (\n)\n(\n)\nK\nK\nP x\nP y\nP x\nP y\nP x\nP y\n\uf03d\n\uf03d\n\uf03d\nProbability of random variable \nX\n and \nY\n  are same, because one to one mapping therefore, entropy of \nrandom variable \nX\n and \nY\n are same. i. e. \n(\n2 )\n( )\nH Y\nX\nH X\n\uf03d\n\uf03d\nSo we will never have situation of \n( )\n(2 )\nH X\nH\nX\n\uf03c\nHence, option \n(B)\n is correct  \nCase-3 : \nAssume new random variable \n2\nX\nY\n \uf03d\n,  This \n2\nX\nY\n \uf03d\n will give one to one mapping because \ndifferent values of\n X\n  provide different values of \nY\n  so that probability of random variable Y is same as \nprobabilities of random variable X so that entropy\n(\n2 )\n(\n)\nX\nH Y\nH X\n\uf03d\n\uf03d\nSo, \n(\n)\n(2 )\nX\nH X\nH\n\uf03c\n never occur\nSo, option (\nC)\n is also correct. \n \nCase-4 : \nAssuming new random variable \n2\nY\nX\n\uf03d\n. \nPossibility-01 : \nSuppose we have 3 positive values of random variable \nX\n  is \n1\n1\nx\n \uf03d\n, \n2\n2,\nx\n \uf03d\n \n3\n3\nx\n \uf03d\n and\nassuming corresponding probabilities of \n1\n2\n3\n,\n,\nx x x\n  are \n1 1 3\n,\n,\n5 2 10\nrespectively\ni.e. \n{1,\n2,\n3}\nX\n \uf03d\nProbability, \n\uf07b\n\uf07d\n1\n1\n3\n(\n)\n,\n,\n5\n2\n10\nP X\n \uf03d\nThus, random variable, \n2\n{1,4,9}\nY\nX\n\uf03d\n\uf03d\n \n \nHere we can say different values of X gives different values of Y, it shows one to one mapping is possible \nbetween X and Y.\nX\nY \nX\n= \n 2\n1\n1\nx\n \uf03d\n1\n1\ny\n \uf03d\n2\n2\nx\n \uf03d\n2\n4\ny\n \uf03d\n3\n3\nx\n \uf03d\n3\n9\ny\n \uf03d\nFig. One to one mapping \n \nSo, probabilities of random variable Y is same as probability of random variable \nX\n.\nIt means, \n1\n1\n3\n( )\n,\n,\n(\n)\n5\n2\n10\nP Y\nP X\n\uf0ec\n\uf0fc\n\uf03d\n\uf03d\n\uf0ed\n\uf0fd\n\uf0ee\n\uf0fe\n\nThus we can say that entropy of \n2\n(\n)\n(\n)\nH X\nH Y\nX\n\uf03d\n\uf03d\n\nGATE 2022 \n [Forenoon Session]\nElectronics & Communication Engineering\nPAGE\n39\n\nPossibility-02 :\n Suppose we have 3 negative values of random variable \nX\n  is \n1\n1\nx\n \uf03d\uf02d\n, \n2\n2\nx\n \uf03d\uf02d\n, \n3\n3\nx\n \uf03d\uf02d\nand assuming corresponding probabilities of \n1\n2\n3\n,\n,\nx x x\n  are \n1 1 3\n,\n,\n5 2 10\nrespectively\ni.e. \n{ 1,\n2,\n3}\nX\n \uf03d\uf02d\n\uf02d\n\uf02d\nProbability, \n\uf07b\n\uf07d\n1\n1\n3\n(\n)\n,\n,\n5\n2\n10\nP X\n \uf03d\nThus, random variable, \n2\n{1,4,9}\nY\nX\n\uf03d\n\uf03d\nHere we can say different values of \nX\n gives different values of \nY\n, it shows one to one mapping is possible \nbetween \nX\n and \nY\n.\nX\nY \nX\n= \n 2\n1\n1\nx\n \uf03d\uf02d\n1\n1\ny\n \uf03d\n2\n2\nx\n \uf03d\uf02d\n2\n4\ny\n \uf03d\n3\n3\nx\n \uf03d\uf02d\n3\n9\ny\n \uf03d\nFig. One to one mapping \n2\nY\nX\n\uf03d\n \n \nSo, probabilities of random variable \nY\n is same as probability of random variable \nX\n,\nIt means, \n1\n1\n3\n( )\n,\n,\n(\n)\n5\n2\n10\nP Y\nP X\n\uf0ec\n\uf0fc\n\uf03d\n\uf03d\n\uf0ed\n\uf0fd\n\uf0ee\n\uf0fe\n\nThus we can say that entropy of \n2\n(\n)\n(\n)\nH X\nH Y\nX\n\uf03d\n\uf03d\n.\nPossibility-03 :\n Suppose we have both positive and negative values of random varible X is \n1\n1\nx\n \uf03d\uf02d\n, \n2\n1\nx\n \uf03d\n, \n3\n2\nx\n \uf03d\n and assuming corresponding probabilities of \n1\nx\n , \n2\nx\n  and \n3\nx\n  are \n1\n5\n \n, \n1\n2\n \n and \n3 .\n10\ni.e. \n{ 1, 1,\n2}\nX\n \uf03d\uf02d\nProbability of \nX\n, \n1\n1\n3\n(\n)\n,\n,\n5\n2\n10\nP X\n\uf0ec\n\uf0fc\n\uf03d\uf0ed\n\uf0fd\n\uf0ee\n\uf0fe\n\nThus random variable, \n2\n{1, 1,\n4}\nY\nX\n\uf03d\n\uf03d\nHere we see different values of X gives same value of Y, it show one to one mapping is not possible here.\nX\nY \nX \n=\n2\n1\n1\nx\n \uf03d\uf02d\n1\n1\ny\n \uf03d\n2\n1\nx\n \uf03d\n3\n2\nx\n \uf03d\n2\n4\ny\n \uf03d\nFig. Mapping of \n2\nY\nX\n\uf03d\n \n \nSo, random variable \nY\n have only 2-values i.e. \n[1,4]\nY\n \uf03d\nSo, probability of \n1\n(\n1)\nP y\n \uf03d\n is sum of probability of \n1\n(\n1)\nP x\n \uf03d\uf02d\n and \n2\n(\n1)\nP x\n \uf03d\n so, \n1\n1\n1\n7\n(\n1)\n5\n2\n10\nP y\n \uf03d\n\uf03d\n\uf02b\n\uf03d\n\nGATE 2022 \n [Forenoon Session]\nElectronics & Communication Engineering\nPAGE\n40\n\nProbability of \n2\n(\n4)\nP y\n \uf03d\n remains same as probability of \n3\n(\n2)\nP x\n \uf03d\n.\ni.e.  \n2\n3\n3\n(\n4)\n(\n2)\n10\nP y\nP x\n\uf03d\n\uf03d\n\uf03d\n\uf03d\nSo entropy of \n( )\nH Y\n  is\n1\n1\n( )\n(\n1)log\n(\n4)log\n(\n1)\n(\n4)\nH Y\nP y\nP y\nP y\nP y\n\uf03d\n\uf03d\n\uf02b\n\uf03d\n\uf03d\n\uf03d\n1\n2\n2\n2\n1\n2\n\n2\n2\n7\n10\n3\n10\nlog\nlog\n10\n7\n10\n3\n\uf03d\n\uf02b\n0.265\n\uf03d\nEntropy of \n( )\nH X\n  is,\n1\n1\n1\n(\n1)log\n(\n1)log\n(\n2)log\n(\n1)\n(\n1)\n(\n2)\nP x\nP x\nP x\nP x\nP x\nP x\n\uf03d\n\uf03d\uf02d\n\uf02b\n\uf03d\n\uf02b\n\uf03d\n\uf03d\uf02d\n\uf03d\n\uf03d\n1\n2\n2\n2\n3\n2\n1\n2\n3\n2\n2\n2\n1\n1\n3\n10\nlog 5\nlog 2\nlog\n5\n2\n10\n3\n\uf03d\n\uf02b\n\uf02b\n0.4643 0.5 0.521089\n\uf03d\n\uf02b\n\uf02b\n1.4854\n\uf03d\nFrom Case-4, it is clear that \n2\n(\n)\n(\n)\nH X\nH X\n\uf03d\n is possible only when random variable \nX \nhave all positive or\nnegative values and \nX\n can take combination of positive and negative values then \n2\n(\n)\n(\n)\nH X\nH X\n\uf03e\n that \nwhy option (D) is incorrect.\nHence, the correct options are (A), (B) & (C).",
  "explanation_text": "Sol.\n \nGiven :\nFor option (A) :\nNoise margin high \n(\n)\nH\nNM\n and Noise margin low \n(\n)\nL\nNM\n is depends on the following parameters of \nMOSFET.\n(i) Size of \nn\n MOSFET and \np \nMOSFET\n(ii) Threshold voltage of \nn\n MOSFET and \np \nMOSFET.\nNoise Margin High is equal to Noise Margin Low if\nW\nW\nL\nL\n\uf0e6\n\uf0f6\n\uf0e6\n\uf0f6\n\uf03d\n\uf0e7\n\uf0f7\n\uf0e7\n\uf0f7\n\uf0e8\n\uf0f8\n\uf0e8\n\uf0f8\n(i)\n\nn\np\n(ii) \nTn\nTp\nV\nV\n\uf03d\nIf\nW\nW\nL\nL\n\uf0e6\n\uf0f6\n\uf0e6\n\uf0f6\n\uf0b9\n\uf0e7\n\uf0f7\n\uf0e7\n\uf0f7\n\uf0e8\n\uf0f8\n\uf0e8\n\uf0f8\n(i)\n\nn\np\n(ii) \nTn\nTp\nV\nV\n\uf0b9\n then \nH\nL\nNM\nNM\n\uf0b9\n.\nSo, option (A) is incorrect.\nFor option (B) :\nMobility is the ability of charge carrier to move freely or be easily moved.\nThe mobility of electrons influences the switching speed because propagation delay \n( )\n\uf074\n depends on \nmobility.\nPLH\nPHL\n\uf074\n\uf02b\uf074\n\uf074\uf03d\nPropagation delay, \n2\nC V\nW\nC\nV\nV\nL\n\uf074\n\uf03d\n\uf0e6\n\uf0f6\n\uf06d\n\uf02d\n\uf0e7\n\uf0f7\n\uf0e8\n\uf0f8\nL\nDD\nPLH\nWhere,\n\n2\n(\n)\np\nox\nGS\nTp\nC V\nW\nC\nV\nV\nL\n\uf074\n\uf03d\n\uf0e6\n\uf0f6\n\uf06d\n\uf02d\n\uf0e7\n\uf0f7\n\uf0e8\n\uf0f8\nL\nDD\nPHL\n\n\n2\n(\n)\nn\nox\nGS\nTn\nIf mobility of electrons \n(\n)\nn\n\uf06d\n increases, \nPHL\n\uf074\n decreases. Therefore propagation delay \n( )\n\uf074\n decrease.\nSo, option (B) is incorrect.\nFor option (C) :\nThe transfer characteristic of practical CMOS inverter is given by,\n\nGATE 2022 \n [Forenoon Session]\nElectronics & Communication Engineering\nPAGE\n35\n\n\nRegion\nNMOS\nPMOS\nin\nV\n0\nV\nAB\nCut-o   ff\nLinear\n0\nin\nTh\nN\nV\nV\n\uf03c\n\uf03c\n0\nDD\nV\nV\n\uf03d\nDD\nTh\nN\nV\nV\nV\n\uf03c\n\uf03c\n0\n2\nDD\nDD\nV\nV\nV\n\uf03c\n\uf03c\nBC\nSaturation\nLinear\n2\nin\nDD\nin\nV\nV\n \uf03d\n0\n2\nDD\nV\nV\n \uf03d\nCC'\nSaturation\nSaturation\n2\nDD\nin\nDD\nTh\nP\nV\nV\nV\nV\n\uf03c\n\uf03c\n\uf02d\nDD\nV\nV\n \uf03c\nC'D\nLinear\nSaturation\n2\n0\n2\nDE\nLinear\nCut- off \nin\nDD\nTh\nP\nV\nV\nV\n\uf03e\n\uf02d\n0\n0V\nV\n \uf0bb\nFor a logical high input under steady state, the \nn\n MOSFET is in the linear regime of operation. \n \nSo, option (C) is correct.  \n \nFor option (D) : \n \nPower dissipation in CMOS inverter : \n \n(i) Static power :\nFig. (a)  \n \n \n \n \n                    Fig. (b) \n \n  \n(a)\n Static power exists due to leakage current in stable state or steady state of CMOS inverter. \n \n  \n(b)\n \n\uf028\n\uf029\nstatic\nD\nP\nleakage\nDD\nV\nI\n\uf03d\n\uf0b4\nwhere, \nleakage\nleakage(NMOS)\nleakage(PMOS)\nI\nI\nI\n\uf03d\n\uf02b\n\nGATE 2022 \n [Forenoon Session]\nElectronics & Communication Engineering\nPAGE\n36\n\n(c)\n Static power is the power consumed by the MOSFET during stable state i.e. it is the power \nconsumed by MOSFET during continuously ON at logic 1 and continuously OFF at logic 0. \n \n \n(ii) Dynamic capacitive power :\nFig. (a) \n \n \n \n      Fig. (b)\nFig. (c)  \n \n \n \n           Fig. (d) \n \n \n(a) It is the power consumed by the MOSFET during its transition state i.e. power consumed by the \nMOSFET during logic 1 to logic 0 or logic 0 to logic 1. \n \n \n(b) It depends on charging and discharging of capacitive load. \n \n \n(c) It is also referred as switching power dissipation.\n(d) Energy stored in PMOS, \n2\n(PMOS)\n1\n2\nD\nDD\nE\nCV\n\uf03d\nEnergy stored in NMOS, \n2\n(NMOS)\n1\n2\nD\nDD\nE\nCV\n\uf03d\nEnergy stored in CMOS, \n2\n(CMOS)\n(NMOS)\n(PMOS)\nD\nD\nD\nDD\nE\nE\nE\nCV\n\uf03d\n\uf02b\n\uf03d\nDynamic power dissipation of CMOS inverter,\n(CMOS)\ndynamic(CMOS)\nD\nE\nP\nT\n\uf03d\n\n2\ndynamic(CMOS)\nSW\nDD\nP\nf\nCV\n\uf03d\nSW\nf\n= Switching frequency\nSW\nf\nf\n\uf03d\uf061\nWhere, \n\uf061\uf03d\n Activity factor (\n0\n1\n\uf03c\uf061\uf03c\n) and \nf\n \uf03d\n operating frequency.\n\nGATE 2022 \n [Forenoon Session]\nElectronics & Communication Engineering\nPAGE\n37\n\nIf \n\uf061\n is not mentioned then we assume \n1\n\uf061\uf03d\n. \n \nTherefore, dynamic power consumption during switching is non-zero. \n \nSo, option (D) is incorrect. \n \nHence, the correct option is (C). \nQuestion 29 \n(MSQ)\n \n \n \nCommunication\n \n \nLet \n( )\nH X\n  denote the entropy of a discrete random variable \n\ud835\udc4b\n taking \n\ud835\udc3e\n possible distinct real values. Which\nof the following statements is/are necessarily true?\n(A) \n2\n(\n)\nlog\nH X\nK\n\uf0a3\n bits \n(B) \n(\n)\n(2 )\nX\nH X\nH\n\uf0a3\n(C) \n( )\n(2 )\nH X\nH\nX\n\uf0a3\n \n(D) \n2\n(\n)\n(\n)\nH X\nH X\n\uf0a3"
}